{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handwritten Digit Recognition using Convolutional Neural Networks\n",
    "\n",
    "This notebook demonstrates how to build a Convolutional Neural Network (CNN) for recognizing handwritten digits using the popular MNIST dataset. The MNIST dataset consists of 28x28 grayscale images of handwritten digits (0 to 9) and the corresponding labels. The dataset is split into 60,000 training images and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "\n",
    "    \"train\": DataLoader(\n",
    "                        train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1\n",
    "    ),\n",
    "\n",
    "    \"test\": DataLoader(\n",
    "                        test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1\n",
    "    )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x192fe24bb20>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x192fe24b550>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) # this is a max pooling layer\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) # this is a dropout layer\n",
    "        x = x.view(-1, 320) # flatten\n",
    "        x = F.relu(self.fc1(x)) # here we can add more layers\n",
    "        x = F.dropout(x, training=self.training) \n",
    "        x = self.fc2(x) # output layer\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303913\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.285569\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.199565\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.086722\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.688686\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.448299\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.070254\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 1.118411\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.887336\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.940290\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.961388\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.773763\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.836639\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.715670\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.570816\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.833408\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.666863\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.529134\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.721269\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.692619\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.432397\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.568702\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.546501\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.459606\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.448249\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.554394\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.518102\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.542838\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.335880\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.389818\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.531095\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.710154\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.588909\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.361154\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.531064\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.546922\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.301110\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.374144\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.505317\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.403471\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.314692\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.413633\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.391360\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.448571\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.456253\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.439263\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.596571\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.483018\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.355641\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.508424\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.502997\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.423032\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.367676\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.494913\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.413024\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.280652\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.399052\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.361718\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.426085\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.464933\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 9557/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.567668\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.365596\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.299943\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.499465\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.177863\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.361470\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.264144\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.369042\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.331388\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.215819\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.419255\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.365785\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.290281\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.345460\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.232048\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.368454\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.415889\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.421934\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.453264\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.456109\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.300979\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.235167\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.354644\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.265157\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.424057\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.282031\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.326887\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.337275\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.241880\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.251321\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.381464\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.300799\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.229058\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.241019\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.373665\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.259757\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.193916\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.309952\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.292640\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.244411\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.233729\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.351171\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.308449\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.401367\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.375499\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.229866\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.209104\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.315734\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.243922\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.198064\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.327620\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.221955\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.233630\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.469915\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.368215\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.272360\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.188213\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.517305\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.210544\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.333214\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 9690/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loaders[\"train\"].dataset),\n",
    "                100. * batch_idx / len(loaders[\"train\"]), loss.item()))\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(loaders[\"test\"].dataset),\n",
    "        100. * correct / len(loaders[\"test\"].dataset)))\n",
    "    \n",
    "for epoch in range(1, 3):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[7]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "pred = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {pred}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
